{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4GaRqgD25Qc",
        "outputId": "c7a23918-d2d1-4317-e067-2deb75df8c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/neww.zip\", \"dinnerTrayBreakfastTray/\")"
      ],
      "metadata": {
        "id": "e3tWat4x3sqr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# Import the Desired Version of EfficientNet\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# Variables\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "train_path = \"/content/dinnerTrayBreakfastTray/new/training\"\n",
        "valid_path = \"/content/dinnerTrayBreakfastTray/new/valid\"\n",
        "test_path = \"/content/dinnerTrayBreakfastTray/new/test\"\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "model_save_location = \"/content/newsave\"\n",
        "\n",
        "\n",
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        preprocessing.RandomRotation(factor=0.15),\n",
        "        preprocessing.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "        preprocessing.RandomFlip(),\n",
        "        preprocessing.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")\n",
        "\n",
        "def build_model(NUM_CLASSES):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    x = img_augmentation(inputs)\n",
        "\n",
        "    #Using the imported version of EfficientNet\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "def test_model(model,test_batches):\n",
        "    #Testing the Model\n",
        "    test_labels = test_batches.classes\n",
        "    print(\"Test Labels\",test_labels)\n",
        "    print(test_batches.class_indices)\n",
        "\n",
        "    predictions = model.predict(test_batches,steps=len(test_batches),verbose=0)\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(len(test_labels)):\n",
        "        actual_class = test_labels[i]\n",
        "        if predictions[i][actual_class] > 0.5 :\n",
        "            acc += 1\n",
        "    print(\"Accuarcy:\",(acc/len(test_labels))*100,\"%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_model(NUM_CLASSES)\n",
        "    unfreeze_model(model)\n",
        "\n",
        "    train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "        directory=train_path, target_size=(224,224), batch_size=10)\n",
        "    valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "        directory=valid_path, target_size=(224,224), batch_size=10)\n",
        "    test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet.preprocess_input).flow_from_directory(\n",
        "        directory=test_path, target_size=(224,224), batch_size=10, shuffle=False)\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath='mymodel.h5',\n",
        "                               verbose=2,save_best_only=True)\n",
        "    callbacks = [checkpoint]\n",
        "    start = datetime.now()\n",
        "\n",
        "\n",
        "\n",
        "    _ = model.fit(train_batches,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=valid_batches, callbacks=callbacks,\n",
        "                  verbose=1)\n",
        "\n",
        "    duration = datetime.now() - start\n",
        "    print(\"Training completed in time: \", duration)\n",
        "    #Testing the Model\n",
        "    test_model(model,test_batches)\n",
        "\n",
        "    # Save the tensorflow Model\n",
        "    #model.save(model_save_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH6JxYs73vuL",
        "outputId": "73214e2c-2f1f-45c5-a7f7-8735fffa8829"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 389 images belonging to 2 classes.\n",
            "Found 29 images belonging to 2 classes.\n",
            "Found 17 images belonging to 2 classes.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
            "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - ETA: 0s - loss: 0.3095 - accuracy: 0.8715\n",
            "Epoch 1: val_loss improved from inf to 0.19757, saving model to mymodel.h5\n",
            "39/39 [==============================] - 26s 387ms/step - loss: 0.3095 - accuracy: 0.8715 - val_loss: 0.1976 - val_accuracy: 0.9655\n",
            "Epoch 2/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9486\n",
            "Epoch 2: val_loss improved from 0.19757 to 0.09717, saving model to mymodel.h5\n",
            "39/39 [==============================] - 13s 320ms/step - loss: 0.1422 - accuracy: 0.9486 - val_loss: 0.0972 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9717\n",
            "Epoch 3: val_loss improved from 0.09717 to 0.05935, saving model to mymodel.h5\n",
            "39/39 [==============================] - 12s 313ms/step - loss: 0.0929 - accuracy: 0.9717 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9769\n",
            "Epoch 4: val_loss improved from 0.05935 to 0.03419, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 350ms/step - loss: 0.0648 - accuracy: 0.9769 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9743\n",
            "Epoch 5: val_loss improved from 0.03419 to 0.01757, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 352ms/step - loss: 0.0819 - accuracy: 0.9743 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0584 - accuracy: 0.9794\n",
            "Epoch 6: val_loss improved from 0.01757 to 0.01188, saving model to mymodel.h5\n",
            "39/39 [==============================] - 13s 341ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9717\n",
            "Epoch 7: val_loss improved from 0.01188 to 0.00829, saving model to mymodel.h5\n",
            "39/39 [==============================] - 11s 287ms/step - loss: 0.0658 - accuracy: 0.9717 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9923\n",
            "Epoch 8: val_loss improved from 0.00829 to 0.00701, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 351ms/step - loss: 0.0327 - accuracy: 0.9923 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9923\n",
            "Epoch 9: val_loss improved from 0.00701 to 0.00395, saving model to mymodel.h5\n",
            "39/39 [==============================] - 13s 338ms/step - loss: 0.0367 - accuracy: 0.9923 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9974\n",
            "Epoch 10: val_loss improved from 0.00395 to 0.00257, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 358ms/step - loss: 0.0125 - accuracy: 0.9974 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000\n",
            "Epoch 11: val_loss improved from 0.00257 to 0.00182, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 350ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9949\n",
            "Epoch 12: val_loss improved from 0.00182 to 0.00146, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 358ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9871\n",
            "Epoch 13: val_loss did not improve from 0.00146\n",
            "39/39 [==============================] - 11s 279ms/step - loss: 0.0220 - accuracy: 0.9871 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 14: val_loss did not improve from 0.00146\n",
            "39/39 [==============================] - 13s 342ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9949\n",
            "Epoch 15: val_loss improved from 0.00146 to 0.00131, saving model to mymodel.h5\n",
            "39/39 [==============================] - 13s 331ms/step - loss: 0.0260 - accuracy: 0.9949 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9974\n",
            "Epoch 16: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 11s 276ms/step - loss: 0.0123 - accuracy: 0.9974 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9974\n",
            "Epoch 17: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 13s 339ms/step - loss: 0.0171 - accuracy: 0.9974 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9923\n",
            "Epoch 18: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 13s 339ms/step - loss: 0.0137 - accuracy: 0.9923 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.9897\n",
            "Epoch 19: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 12s 302ms/step - loss: 0.0394 - accuracy: 0.9897 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9897\n",
            "Epoch 20: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 12s 300ms/step - loss: 0.0273 - accuracy: 0.9897 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9974\n",
            "Epoch 21: val_loss did not improve from 0.00131\n",
            "39/39 [==============================] - 13s 339ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9846\n",
            "Epoch 22: val_loss improved from 0.00131 to 0.00035, saving model to mymodel.h5\n",
            "39/39 [==============================] - 13s 344ms/step - loss: 0.0392 - accuracy: 0.9846 - val_loss: 3.5326e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9871\n",
            "Epoch 23: val_loss did not improve from 0.00035\n",
            "39/39 [==============================] - 11s 292ms/step - loss: 0.0337 - accuracy: 0.9871 - val_loss: 5.6343e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 24: val_loss did not improve from 0.00035\n",
            "39/39 [==============================] - 12s 306ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 8.7743e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9974\n",
            "Epoch 25: val_loss did not improve from 0.00035\n",
            "39/39 [==============================] - 12s 302ms/step - loss: 0.0063 - accuracy: 0.9974 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9949\n",
            "Epoch 26: val_loss improved from 0.00035 to 0.00035, saving model to mymodel.h5\n",
            "39/39 [==============================] - 16s 425ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 3.4724e-04 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.00035\n",
            "39/39 [==============================] - 12s 300ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.3303e-04 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9949\n",
            "Epoch 28: val_loss did not improve from 0.00035\n",
            "39/39 [==============================] - 12s 300ms/step - loss: 0.0127 - accuracy: 0.9949 - val_loss: 4.7206e-04 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9743\n",
            "Epoch 29: val_loss improved from 0.00035 to 0.00032, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 350ms/step - loss: 0.0486 - accuracy: 0.9743 - val_loss: 3.2387e-04 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9923\n",
            "Epoch 30: val_loss improved from 0.00032 to 0.00025, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 355ms/step - loss: 0.0273 - accuracy: 0.9923 - val_loss: 2.4802e-04 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9897\n",
            "Epoch 31: val_loss did not improve from 0.00025\n",
            "39/39 [==============================] - 11s 293ms/step - loss: 0.0207 - accuracy: 0.9897 - val_loss: 4.8153e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 0.9949\n",
            "Epoch 32: val_loss did not improve from 0.00025\n",
            "39/39 [==============================] - 12s 311ms/step - loss: 0.0185 - accuracy: 0.9949 - val_loss: 2.7533e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9846\n",
            "Epoch 33: val_loss improved from 0.00025 to 0.00009, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 353ms/step - loss: 0.0383 - accuracy: 0.9846 - val_loss: 8.5058e-05 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 13s 340ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5521e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9949\n",
            "Epoch 35: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 11s 281ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 2.2919e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9974\n",
            "Epoch 36: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 13s 343ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 4.0778e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9974\n",
            "Epoch 37: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 12s 315ms/step - loss: 0.0131 - accuracy: 0.9974 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 13s 342ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.3047e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 13s 325ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.0984e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9974\n",
            "Epoch 40: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 13s 339ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 4.1328e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9846\n",
            "Epoch 41: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 12s 315ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 3.1889e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9923\n",
            "Epoch 42: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 15s 389ms/step - loss: 0.0191 - accuracy: 0.9923 - val_loss: 2.9551e-04 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 0.00009\n",
            "39/39 [==============================] - 12s 294ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.9777e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9949\n",
            "Epoch 44: val_loss improved from 0.00009 to 0.00007, saving model to mymodel.h5\n",
            "39/39 [==============================] - 14s 352ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 6.8121e-05 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9897\n",
            "Epoch 45: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 13s 340ms/step - loss: 0.0412 - accuracy: 0.9897 - val_loss: 4.1617e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9974\n",
            "Epoch 46: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 11s 285ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9871\n",
            "Epoch 47: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 12s 311ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 0.9820\n",
            "Epoch 48: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 13s 340ms/step - loss: 0.0323 - accuracy: 0.9820 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9949\n",
            "Epoch 49: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 13s 325ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 7.5424e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "39/39 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 0.00007\n",
            "39/39 [==============================] - 11s 275ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Training completed in time:  0:11:55.787874\n",
            "Test Labels [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n",
            "{'0': 0, '1': 1}\n",
            "Accuarcy: 100.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.data import AUTOTUNE\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "#--SK\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#--Others\n",
        "import imutils\n",
        "from imutils import paths\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Vn52srxk4O4j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_paths = list(paths.list_images(test_path))\n",
        "testlabels = [int(p.split(os.path.sep)[-2]) for p in test_paths]\n",
        "#turn them into categorical values so we can count them (one hot encoding)\n",
        "testlabels = to_categorical(testlabels)"
      ],
      "metadata": {
        "id": "y2njalRM4Tkq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(test_batches)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5upbZ574UdJ",
        "outputId": "c4b5f1e6-3cbc-46ad-9891-3e27e26a8033"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 195ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Classification Report')\n",
        "print(classification_report(test_batches.classes, y_pred, target_names=[\"0\",\"1\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z00eiESD4V7c",
        "outputId": "ff81a21b-b357-4829-c03b-91ef0dec9bd5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           1.00        17\n",
            "   macro avg       1.00      1.00      1.00        17\n",
            "weighted avg       1.00      1.00      1.00        17\n",
            "\n"
          ]
        }
      ]
    }
  ]
}